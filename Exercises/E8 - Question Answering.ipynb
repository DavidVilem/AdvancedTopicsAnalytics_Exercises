{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center>\n",
        "\n",
        "<div align=\"center\">\n",
        "    <img src=\"../Images/javeriana.PNG\" width=\"800\" height=\"600\">\n",
        "</div>\n",
        "\n",
        "**Juan David Villate Lemus**\n",
        "\n",
        "**José Rafael Peña Gutiérrez**\n",
        "\n",
        "**Laura Katherine Moreno Giraldo**\n",
        "\n",
        "**William Ricardo Fernández Garnica**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question & Answer\n",
        "\n",
        "Creating a Question-Answer Transformer model or QA Transformer can be beneficial for several reasons, particularly in the field of Natural Language Processing (NLP). Here are some compelling reasons why you might want to develop a QA Transformer:\n",
        "\n",
        "1. **Question-Answering Systems:** QA Transformers are designed to provide accurate and contextually relevant answers to questions posed in natural language. These systems have a wide range of practical applications, including chatbots, virtual assistants, customer support, and information retrieval.\n",
        "\n",
        "2. **Information Retrieval:** QA Transformers can be used to search through large corpora of text and extract precise answers to user queries. This can improve the efficiency and effectiveness of information retrieval systems.\n",
        "\n",
        "3. **Document Summarization:** QA Transformers can be used to summarize long documents by answering questions about the document's content. This makes it easier for users to quickly understand the key points and relevant information in a text.\n",
        "\n",
        "4. **Education and E-Learning:** QA Transformers can be integrated into educational platforms to provide instant answers and explanations to students' questions. They can also help with the automatic generation of quiz questions and answers.\n",
        "\n",
        "5. **Content Generation:** QA Transformers can assist in content generation by automatically answering questions based on available knowledge. This can be useful for generating FAQs, product descriptions, and informative articles.\n",
        "\n",
        "6. **Customer Support:** Many companies use QA systems to automate responses to frequently asked questions, freeing up human agents to handle more complex queries and providing customers with quick solutions.\n",
        "\n",
        "7. **Medical Diagnosis:** QA Transformers can assist medical professionals by answering questions related to patient records, medical literature, and diagnostic information, potentially leading to faster and more accurate diagnoses.\n",
        "\n",
        "8. **Legal and Compliance:** In the legal field, QA Transformers can be used to search and extract information from legal documents, assisting lawyers in their research and case preparation.\n",
        "\n",
        "9. **Language Translation:** QA Transformers can be used to answer questions about language translation, helping users understand the meaning of words, phrases, or sentences in different languages.\n",
        "\n",
        "10. **Scientific Research:** QA Transformers can support researchers by answering questions related to scientific literature, allowing them to quickly access relevant information for their studies.\n",
        "\n",
        "11. **Decision Support:** QA Transformers can aid in decision-making processes by providing answers to questions related to data analysis, market research, and business intelligence.\n",
        "\n",
        "12. **Accessibility:** QA Transformers can improve accessibility for individuals with disabilities by providing spoken or written answers to their questions, helping them access information more easily.\n",
        "\n",
        "Overall, QA Transformers have the potential to enhance information retrieval, automation, and user interaction in various domains, making them a valuable tool in the development of intelligent systems and applications. The ability to provide accurate and context-aware answers to questions in natural language is a key advantage of these models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "Exercise:\n",
        "\n",
        "Now, as a data scientist expert in NLP, you are asked to create a model to be able to answer question in Spanish. Your stakeholders will pass you an article and one question and your model should answer it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (2.27.1)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (4.11.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from requests) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from requests) (2.10)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\appdata\\local\\programs\\pythoncodingpack\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: There was an error checking the latest version of pip.\n"
          ]
        }
      ],
      "source": [
        "pip install requests beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Over the course of February, Geoffrey Hinton, one of the most influential AI researchers of the past 50 years, had a “slow eureka moment.”\n",
            "Hinton, 76, has spent his career trying to build AI systems that model the human brain, mostly in academia before joining Google in 2013. He had always believed that the brain was better than the machines that he and others were building, and that by making them more like the brain, they would improve. But in February, he realized “the digital intelligence we’ve got now may be better than the brain already. It’s just not scaled up quite as big.” \n",
            "Developers around the world are currently racing to build the biggest AI systems that they can. Given the current rate at which AI companies are increasing the size of models, it could be less than five years until AI systems have 100 trillion connections—roughly as many as there are between neurons in the human brain.\n",
            "Alarmed, Hinton left his post as VP and engineering fellow in May and gave a flurry of interviews in which he explained that he had left in order to be able to speak freely on the dangers of AI—and his regrets over helping bring that technology into existence. He worries about what could happen once AI systems are scaled up to the size of human brains—and the prospect of humanity being wiped out by the technology he helped create. “This stuff will get smarter than us and take over,” says Hinton. “And if you want to know what that feels like, ask a chicken.”\n",
            "Born and raised in England, Hinton comes from a long line of luminaries, with relatives including the mathematician Mary Everest Boole and logician George Boole, whose work is crucial to modern computer science; surgeon James Hinton; and surveyor George Everest, who gave his name to the mountain. \n",
            "The human brain always fascinated Hinton. As a Cambridge University undergraduate, he tried a range of subjects—physiology, physics, philosophy—before graduating with a degree in experimental psychology in 1970. He worked briefly as a carpenter before starting a Ph.D. in AI at the University of Edinburgh, then the U.K.’s only postgraduate program on the subject, in 1972.\n",
            "In the 1970s, artificial intelligence, after failing to live up to its postwar promise, was going through a period of dampened enthusiasm now referred to as the “AI winter.” In this unfashionable field, Hinton pursued an unpopular idea: AI systems known as neural networks, which mimicked the structure of the human brain. His thesis adviser urged him on a weekly basis to change his approach. Each time he replied, “Give me another six months and I’ll prove to you that it works.”\n",
            "Upon completion of his Ph.D., Hinton moved to the U.S., where more funding was available for his research. He published pathbreaking research, for which he was awarded the 2018 Turing Award, in posts at universities across the U.S., before eventually taking a professorship in computer science at the University of Toronto. Toronto has become Hinton’s home base; he travels relatively infrequently because back problems prevent him from sitting down. During car journeys he lies across the back seat; he eats kneeling before a table “like a monk at the altar”; and as he spoke to TIME he swayed gently in front of a head-height camera.\n",
            "In 2012, Hinton and two of his graduate students, Alex Krizhevsky and Ilya Sutskever, now chief scientist at OpenAI, entered ImageNet, a once annual competition in which researchers competed to build the most accurate image-recognition AI systems. They dominated the competition—an emphatic demonstration that neural networks had come of age. Hinton’s persistence had paid off.\n",
            "He and his two students began receiving lucrative offers from big tech companies. They set up a shell company called DNN-research to auction their expertise, and four tech firms—Google, Microsoft, Baidu, and DeepMind—bid tens of millions for the company. After a week, Hinton chose Google over the final bidder, Baidu. In 2013, he joined Google Brain, the cutting-edge machine-learning team he left in May.\n",
            "Hinton has been instrumental in the development and popularization of neural networks, the dominant AI development paradigm that has allowed huge amounts of data to be ingested and processed, leading to advances in image recognition, language understanding, and self-driving cars. His work has potentially hastened the future he fears, in which AI becomes superhuman with disastrous results for humans. In an interview with the New York Times, Hinton said, “I console myself with the normal excuse: If I hadn’t done it, somebody else would have.”\n",
            "Hinton does not know how to prevent superhuman AI systems from taking over. If there’s any hope, he says, it lies with the next generation, noting that he feels too old to continue contributing to research. Many scientists switch to policy work later in their careers, but he declined Google’s offer to take such a role at the company. “I’ve never been very good at or interested in policy issues,” he tells TIME. “I’m a scientist.” \n",
            "Instead, Hinton has spent the past few months sounding the alarm—he can explain the technical details of AI in an accessible way as well as anyone and spends much of his time giving interviews to raise public awareness. He has also spoken with policymakers, including officials in the U.K. Prime Minister’s office, Canadian Prime Minister Justin Trudeau, Executive Vice-President of the European Commission Margrethe Vestager, and U.S. Senators Bernie Sanders and Jon Ossoff.\n",
            "While on a theoretical level he now grasps the risks from AI, Hinton says that his emotions haven’t yet caught up. “The idea that we’re going to be replaced as the apex intelligence is just very hard to get your head around.” \n",
            "But for now, he takes his cues from another relative: his cousin Joan Hinton was one of the only women scientists to work on the Manhattan Project. After the nuclear weapons that she helped to create were dropped on Hiroshima and Nagasaki, she became a peace activist. In 1948 she moved to China, and she spent most of the rest of her life working on dairy farms as an ardent Maoist. Hinton’s own retirement plans are less strident but likewise bucolic: he intends to rediscover carpentry and take long walks.\n",
            "Write to Will Henshall at will.henshall@time.com.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# URL del artículo\n",
        "url = \"https://time.com/collection/time100-ai/6309026/geoffrey-hinton/\"\n",
        "\n",
        "# Realizar una solicitud HTTP para obtener el contenido de la página\n",
        "response = requests.get(url)\n",
        "\n",
        "# Verificar si la solicitud fue exitosa\n",
        "if response.status_code == 200:\n",
        "    # Analizar el contenido HTML de la página con BeautifulSoup\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    # Encontrar el contenido del artículo (puedes inspeccionar el HTML de la página para encontrar la estructura adecuada)\n",
        "    article_content = soup.find(\"div\", {\"class\": \"article-content\"})\n",
        "\n",
        "    # Extraer el texto del artículo\n",
        "    article_text = \"\"\n",
        "    for paragraph in article_content.find_all(\"p\"):\n",
        "        article_text += paragraph.get_text() + \"\\n\"\n",
        "\n",
        "    # Imprimir el texto del artículo\n",
        "    print(article_text)\n",
        "else:\n",
        "    print(\"Error al obtener la página:\", response.status_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w5-qn5-4NyJ"
      },
      "source": [
        "**Por favor correr esta celda que carga todo lo necesario para cumplir la funcionalidad**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: There was an error checking the latest version of pip.\n"
          ]
        }
      ],
      "source": [
        "pip install -q transformers torch requests beautifulsoup4 googletrans translate deep_translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importing libraries ---------------------------------\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import pipeline, BertForQuestionAnswering, BertTokenizer\n",
        "from translate import Translator\n",
        "from deep_translator import GoogleTranslator\n",
        "import re\n",
        "from html import unescape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Eliminar etiquetas HTML y corchetes: Utiliza una expresión regular (html_tags_and_brackets_pattern = r'<.*?>|\\[.*?\\]') para identificar y eliminar etiquetas HTML (todo lo que esté entre < y >) así como texto entre corchetes (todo lo que esté entre [ y ]). La expresión <.*?> busca de manera no codiciosa cualquier carácter que esté entre < y >, y \\[.*?\\] hace lo mismo para los corchetes. Esto se hace mediante re.sub(html_tags_and_brackets_pattern, '', text), donde re.sub reemplaza todas las ocurrencias de la expresión regular en text por una cadena vacía (es decir, las elimina).\n",
        "\n",
        "3. Decodificar entidades HTML: Algunos textos contienen entidades HTML, que son representaciones de texto para caracteres especiales. Por ejemplo, &amp; representa el carácter &. La función unescape(text) decodifica estas entidades a sus caracteres correspondientes. Esto es útil porque después de eliminar las etiquetas HTML, todavía pueden quedar entidades HTML que necesitan ser convertidas a un formato legible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Defining some functions -------------------------------\n",
        "def clean_html_text(text):\n",
        "  # Remove html tags\n",
        "  html_tags_and_brackets_pattern = r'<.*?>|\\[.*?\\]'\n",
        "  text = re.sub(html_tags_and_brackets_pattern, '', text)\n",
        "\n",
        "  # Decode HTML entities\n",
        "  text = unescape(text)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**extract_article_text(url)**\n",
        "\n",
        "Esta función está diseñada para extraer el texto de un artículo a partir de su URL. Utiliza la biblioteca requests para hacer una petición HTTP GET a la URL proporcionada y la biblioteca BeautifulSoup para analizar el contenido HTML recibido. A continuación, detallo el proceso paso a paso:\n",
        "\n",
        "- Hacer una petición a la URL: Utiliza requests.get(url) para solicitar el contenido de la página web. url es el parámetro que contiene la dirección web del artículo que se quiere analizar.\n",
        "\n",
        "- Verificar la respuesta: Comprueba el código de estado de la respuesta (response.status_code). Si es 200, significa que la petición fue exitosa y se procede con el análisis del contenido. Si no, se lanza una excepción indicando que no se pudo recuperar la página.\n",
        "\n",
        "- Analizar el contenido HTML: Si la respuesta es exitosa, utiliza BeautifulSoup(response.text, \"html.parser\") para parsear el HTML de la página. BeautifulSoup facilita la navegación y búsqueda en el árbol de elementos HTML.\n",
        "\n",
        "- Extraer el texto del artículo: Inicializa una variable article_text como una cadena vacía. Luego, itera sobre todos los párrafos (<p>) encontrados en el contenido HTML (soup.find_all(\"p\")) y va concatenando el texto de cada párrafo a article_text, añadiendo un espacio al final de cada uno para separar los párrafos.\n",
        "\n",
        "- Limpiar el texto extraído: Antes de devolver el texto del artículo, se llama a la función clean_html_text(article_text) para eliminar cualquier etiqueta HTML residual y decodificar entidades HTML. Esto asegura que el texto devuelto esté limpio y sea legible.\n",
        "\n",
        "- Devolver o lanzar una excepción: Si se encontró contenido en el artículo, se devuelve el texto limpio. Si no, se lanza una excepción indicando que no se encontró contenido en la URL proporcionada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_article_text(url):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        if soup:\n",
        "            article_text = \"\"\n",
        "            for paragraph in soup.find_all(\"p\"):\n",
        "                article_text += paragraph.get_text() + \" \"\n",
        "            article_text = clean_html_text(article_text)\n",
        "            return article_text\n",
        "        else:\n",
        "            raise ValueError(\"No article content found in the provided URL\")\n",
        "    else:\n",
        "        raise ValueError(f\"Failed to retrieve page. Status code: {response.status_code}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Esta función se encarga de traducir un texto a un idioma objetivo utilizando GoogleTranslator, una interfaz para el servicio de traducción de Google. El proceso es simple:**\n",
        "\n",
        "- Traducir el texto: La función recibe dos parámetros: text, que es el texto a traducir, y target, que especifica el código del idioma al que se quiere traducir el texto. Utiliza GoogleTranslator(source='auto', target=target).translate(text) para realizar la traducción. El parámetro source='auto' indica que el idioma original del texto será detectado automáticamente por el servicio.\n",
        "\n",
        "- Devolver la traducción: La traducción resultante se devuelve directamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def translate_text(text, target):\n",
        "    translation = GoogleTranslator(source='auto', target= target).translate(text)\n",
        "    return translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Modelo y Tokenizador: bert-large-uncased-whole-word-masking-finetuned-squad.** \n",
        "\n",
        "Este pipeline utiliza un modelo BERT de tamaño grande (bert-large) que ha sido entrenado específicamente en la tarea de QA con el dataset SQuAD (Stanford Question Answering Dataset). El modelo utiliza \"whole word masking\" durante el preentrenamiento, lo que significa que en lugar de enmascarar partes de palabras (subwords), se enmascaran palabras completas. Esto puede ayudar a mejorar el entendimiento del contexto y la precisión en tareas que dependen de la comprensión del lenguaje a nivel de palabra completa, como es el caso de la respuesta a preguntas. Este pipeline probablemente será más preciso pero también más lento en comparación con el faster_qa_pipeline, debido al mayor tamaño y complejidad del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# Question answering pipelines -------------------------------------------------\n",
        "slower_qa_pipeline = pipeline(\"question-answering\", model= \"bert-large-uncased-whole-word-masking-finetuned-squad\", tokenizer= \"bert-large-uncased-whole-word-masking-finetuned-squad\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Modelo y Tokenizador: distilbert-base-cased-distilled-squad.**\n",
        "\n",
        "Este pipeline utiliza DistilBERT, que es una versión \"destilada\" de BERT. DistilBERT está diseñado para ser más ligero y rápido que BERT, sacrificando una pequeña cantidad de precisión a cambio de una mayor velocidad y menor consumo de recursos. Este modelo en particular ha sido afinado (fine-tuned) también en el dataset SQuAD. Al estar en su variante \"cased\", mantiene la distinción entre mayúsculas y minúsculas, lo cual es relevante para ciertos tipos de comprensión de texto. Este pipeline es una opción más rápida, adecuada para aplicaciones que requieren respuestas en tiempo real o que operan bajo restricciones de recursos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "faster_qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\", tokenizer=\"distilbert-base-cased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Verificación de la URL: La función comienza verificando si se ha proporcionado una URL válida. Si no es así, lanza un error indicando que se necesita una URL.\n",
        "\n",
        "2. Extracción del texto del artículo: Utiliza la función extract_article_text(url) para obtener el texto del artículo de la URL proporcionada. Esta función maneja la solicitud HTTP, analiza el HTML y extrae el texto del artículo, limpiándolo de etiquetas HTML y entidades.\n",
        "\n",
        "3. Preparación de las preguntas:\n",
        "\n",
        "    - Si el argumento question no es una lista, lo convierte en una al encapsular la pregunta en una lista. Esto estandariza el procesamiento posterior, permitiendo manejar tanto una única pregunta como múltiples preguntas.\n",
        "    - Traduce las preguntas al inglés usando la función translate_text(question, 'english'), ya que los modelos de QA utilizados operan en inglés.\n",
        "\n",
        "4. Respuesta a las preguntas:\n",
        "\n",
        "    - Itera sobre las preguntas traducidas, utilizando el modelo de QA de alta precisión (slower_qa_pipeline) si high_accuracy es True, o el modelo más rápido (faster_qa_pipeline) si es False. La elección del pipeline afecta el equilibrio entre precisión y velocidad de respuesta.\n",
        "    - Cada pregunta se pasa junto con el contexto (el texto del artículo) al pipeline seleccionado para obtener una respuesta.\n",
        "\n",
        "5. Traducción y presentación de las respuestas:\n",
        "\n",
        "    - Traduce la respuesta obtenida del modelo de QA al español.\n",
        "    - Almacena la pregunta original y su respuesta traducida como una tupla en la lista answers.\n",
        "    - Finalmente, imprime cada pregunta y su respuesta correspondiente.\n",
        "\n",
        "6. Manejo de excepciones: Si ocurre un error durante el proceso, como un problema de conexión o un error al procesar el texto, la excepción se captura y se imprime un mensaje de error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LhVdjajuDGaB"
      },
      "outputs": [],
      "source": [
        "def answer_questions_spanish(url=None, question='¿De qué trata el artículo?', high_accuracy=True):\n",
        "    if not url:\n",
        "        raise ValueError(\"The function must receive a valid URL\")\n",
        "    try:\n",
        "        article_text = extract_article_text(url)\n",
        "        if type(question) != list:\n",
        "          questions = []\n",
        "          questions.append(question)\n",
        "        else:\n",
        "          questions = question\n",
        "        # Translate questions\n",
        "        translated_questions = [translate_text(x, 'english') for x in questions]\n",
        "\n",
        "        answers = []\n",
        "        for index, q in enumerate(translated_questions):\n",
        "          if high_accuracy:\n",
        "            answer = slower_qa_pipeline(question=q, context=article_text)\n",
        "          else:\n",
        "            answer = faster_qa_pipeline(question=q, context=article_text)\n",
        "          information = (questions[index], translate_text(answer['answer'], 'spanish'))\n",
        "          answers.append(information)\n",
        "        for question, answer in answers:\n",
        "          print(f'Pregunta: {question}\\nRespuesta: {answer}')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbrfIzpJ4usY"
      },
      "source": [
        "## Para usar este servicio, por favor usa la función answer_question_spanish() con los siguientes argumentos:\n",
        "\n",
        "*   url (string): El link del documento del cuál quisiera hacer preguntas\n",
        "*   question (string or list): La pregunta o la lista de preguntas que tenga respecto al texto\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmcfH5wn58Nq"
      },
      "source": [
        "#### Artículo sobre Geoffrey Hinton"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Al ejecutar la función answer_questions_spanish con la URL y la pregunta dadas, la función intentará:**\n",
        "\n",
        "- Extraer el texto del artículo proporcionado en la URL.\n",
        "- Traducir la pregunta al inglés.\n",
        "- Utilizar el pipeline de QA seleccionado para encontrar una respuesta en el contexto del artículo.\n",
        "- Traducir la respuesta encontrada al español.\n",
        "- Imprimir la pregunta y su respuesta en consola."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDb4B9USxdNQ",
        "outputId": "648bbcb6-700c-4995-c5a5-96ca4426b158"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pregunta: ¿Cuales materias vio Hinton en la universidad?\n",
            "Respuesta: fisiología, física, filosofía\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "url = \"https://time.com/collection/time100-ai/6309026/geoffrey-hinton/\"\n",
        "question = \"¿Cuales materias vio Hinton en la universidad?\"\n",
        "answer_questions_spanish(url=url, question=question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pdHLLxc0pJY",
        "outputId": "f3e6c9d8-d87c-4afa-dcdb-a61dd6f6f795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pregunta: ¿Cuales materias vio Hinton en la universidad?\n",
            "Respuesta: fisiología, física, filosofía\n",
            "Pregunta: ¿Cuales son los nombres de los estudiantes de Hinton con los cuales ganó una competición?\n",
            "Respuesta: Alex Krizhevsky e Ilya Sutskever\n",
            "Pregunta: ¿Que premios ha ganado Hinton durante su carrera?\n",
            "Respuesta: Premio Turing 2018\n",
            "Pregunta: ¿Que pensaba el supervisor de tesis de Hinton respecto a su trabajo?\n",
            "Respuesta: Lo instó semanalmente a cambiar su enfoque.\n",
            "Pregunta: ¿Por qué Hinton abandonó la vicepresidencia de la Comisión Europea?\n",
            "Respuesta: poder hablar libremente sobre los peligros de la IA\n"
          ]
        }
      ],
      "source": [
        "url = \"https://time.com/collection/time100-ai/6309026/geoffrey-hinton/\"\n",
        "question = [\"¿Cuales materias vio Hinton en la universidad?\",\n",
        "            \"¿Cuales son los nombres de los estudiantes de Hinton con los cuales ganó una competición?\",\n",
        "            \"¿Que premios ha ganado Hinton durante su carrera?\",\n",
        "            \"¿Que pensaba el supervisor de tesis de Hinton respecto a su trabajo?\",\n",
        "            \"¿Por qué Hinton abandonó la vicepresidencia de la Comisión Europea?\"]\n",
        "answer_questions_spanish(url=url, question=question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZMzQf0a5_F-"
      },
      "source": [
        "#### Wikipedia Andrew Ng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQBcgA6p6WlW",
        "outputId": "fc84936e-6c4e-4667-8e94-49a7b3b34872"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pregunta: ¿Cuál es el título de pregrado que obtuvo Andrew Ng?\n",
            "Respuesta: informática, estadística y economía\n"
          ]
        }
      ],
      "source": [
        "url = \"https://en.wikipedia.org/wiki/Andrew_Ng\"\n",
        "question = \"¿Cuál es el título de pregrado que obtuvo Andrew Ng?\"\n",
        "answer_questions_spanish(url=url, question=question)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
